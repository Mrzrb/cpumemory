# 介绍

> 早些年，计算机构造非常简单，CPU、内存、存储、网络接口等都被设计在一起，并且他们的性能相当匹配，性能均衡(其实是很慢)。

![](http://zhangrb-image.oss-cn-beijing.aliyuncs.com/image/20190905162555.png)

当计算机体系结构趋于稳定的时候，硬件工程师坐不住了，这也太慢了，所以他们在各个子系统上钻研，于是乎，百花争鸣各个硬件速度都有了提升，但是肯定有发展速度不如别的子系统的系统，参考木桶效应，这些子系统就成为了整个系统运行速度的瓶颈，特别是IO相对于别的系统来说就太慢了。

![](http://zhangrb-image.oss-cn-beijing.aliyuncs.com/image/20190905163041.png)

人们想到了一个好办法， 他们把最常用以及最可能用到的数据放到了最容易拿到的地方(Cache)，Cache是一个比外部存储以及网络IO快很多的硬件系统自带的缓存，所以，如果我们使用得当，是可以在不大规模改变硬件的前提下缓解IO过慢导致整个系统运行缓慢。

和存储不同，想要改变主存已经被证明非常困难，几乎所有的方案都需要对硬件进行一定的改造，有如下几种途径：
  1. RAM硬件的设计(速度上和并行度上)
  2. 内存控制器的设计
  3. CPU缓存
  4. 设备DMA (Direct memory access)

本文只讨论CPU缓存和内存控制器的设计。在讨论这些主题的过程中，我们会详细的探索DMA，在那之前，我们将会回顾一下线代商业硬件的设计。这对理解内存在使用过程中的问题以及局限很有帮助。我们还会讨论不同类型的RAM之前的区别以及为啥会有这些区别。


> 本文设计到操作系统的时候,一般指Linux。

## 本文组织结构

本文主要是面向软件开发者，不会过多的讨论硬件系统的细节。

第一部分介绍一些必要的硬件知识，以便读者可以更好的了解后面的内容。

第二部分我们详细介绍了RAM，这部分内容很棒， 但是读者可以跳过这部分，后面有这部分知识的时候可以返回来看相关的内容即可。

第三部分详细的介绍了CPU cache。理解这部分内容对于后续部分的理解非常重要。

第四部分介绍了虚拟内存相关的内容。

第五部分介绍了NUMA系统 (Non Uniform Memory Access)

第六部分是本文的重点，这一张涉及到了前面的所有章节，并且给开发者很多写出高性能程序的建议，只对优化程序相关感兴趣的读者可以直接从这部分开始， 遇到相关内容可以回溯之前的章节。

第七部分介绍了一些帮助开发者处理一些系统问题的工具。

第八部分我们展望了未来相关技术的走向。

好了，话不多说，让我们一起开始正文吧！

![](http://zhangrb-image.oss-cn-beijing.aliyuncs.com/image/20190905200306.png)
